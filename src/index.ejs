<!doctype html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style id="distill-article-specific-styles">
    <%=require("../static/styles.css") %>
  </style>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="https://kit.fontawesome.com/a076d05399.js"></script>
  <script src="https://distill.pub/template.v2.js"></script>
</head>

<body>

  <d-front-matter>
    <script type="text/json">
      <%= JSON.stringify(require("./frontmatter.json"), null, 4) %>
    </script>
  </d-front-matter>

  <d-title>
    <h1>Gaussian Belief Propagation for Spatial AI</h1>
    <p>A visual introduction to Gaussian Belief Propagation for realtime computer vision. </p>
  </d-title>

  <d-article>
    <d-contents>
      <nav class="l-text toc figcaption">
        <h3>Contents</h3>
        <div><a href="#spatialAI">Spatial AI</a></div>
        <div><a href="#gbp">Gaussian Belief Propagation</a></div>
        <div><a href="#related">Related Work</a></div>
        <div><a href="#theory">A brief Theoretical Background</a></div>
        <div><a href="#simulations">Simulated Geometric Estimation Problems</a></div>
        <ul>
          <li><a href="#1dsurface">1D Surface Fitting</a></li>
          <li><a href="#2drobot">2D Robot Simulation</a></li>
        </ul>
        <div><a href="#discussion">Discussion</a></div>
      </nav>
    </d-contents>

    <h2 id="spatialAI">Spatial AI </h2>
    <p>We want to build intelligent robots that can interact with their environments. An intelligent agent must be capable of spatial reasoning, which requires a component that can build representations of the environment, while also continuosly updating the representation. These representations should capture the geometry, semantic properties, physical properties and other information about the environment.  </p>

    <p>To draw analogy to humans, we have grid cells ect... evidence for map building in human brains. </p>

    <p>We call this general spatial perception capability <i><b>Spatial AI</b></i> <d-cite key="davison2018futuremapping"></d-cite>. We believe that SLAM will evolve into Spatial AI.</p>

    <p>What capabilities do we need: Consistency, long term persistence, abstraction and efficiency</p>
    <p>Why? To enable intelligence! A robot will have a model of the world which is a simulation of reality based on all of its prior knowledge and ongoing experience; and be able to use it to make intelligent e.g. causal inferences about action. I believe in persistent scene representation for spatial reasoning. The foundation for higher level AI?</p>

    <h3 id="slam">Current Landscape of SLAM Algorithms </h2>

    <p>We begin the discussion of how to build a system capable of Spatial AI by examining existing works in that direction. Note, we have not specified whether the representation should derscribe metric geometry of be abstract. Core capabilities are dense geometry and object class understanding: ElasticFusion, SemanticFusion: how to do it properly?</p>

    <p>What hardware is used in current practical SLAM systems? </p>


    <figure class="l-body">
      <d-figure id=""></d-figure>
        <figcaption>Toy visualisation of data flow and compute on current CPUs / GPUs.</figcaption>
      </figure>
    </figure>

    Discussion of bits x milimetres metric. 

    What current graph processing hardware is emerging. How would a message passing inference algorithm be well satisfy practical constraints. 

    <figure class="l-body">
      <d-figure id=""></d-figure>
        <figcaption>Toy visualisation of data flow and compute on graph processor.</figcaption>
      </figure>
    </figure>

    <h2 id="gbp">Why Gaussian Belief Propagation? </h2>

    <p>We argue that Gaussian Belief Propagation (GBP) is a strong algorithmic framework for the distributed, generic and incremental probabilistic estimation that we need in Spatial AI. Here we describe how GBP can be the foundation for high performance smart robots and devices which operate within the constraints of real products.</p>

    <h3>Low power requires distributed computation and storage to fit new hardware
    </h3>
    <p> Sending data is costly in power comsumption. </p>
    <p>-> Message passing between processors with local computation and memory, either on a single chip or across multiple simple devices.</p> 

    <h3> Probabilistic fusion of heterogeneous inputs</h3>
    <p> A robot will need to probabilistically fuse different measurements and priors to jointly estimate its current state and optimise its representation of the environment. Bayesian probability theory, from which Gaussian Belief Propagation can be derived, provides a framework to combine constraints and perform probabilistic inference. </p> 

    <h3>We can build persistent and flexible representations from incremental measurements</h3>
    <p> <b>Flexibility</b>: Factor graphs can hold any combination of arbitary entities. This enables a natural interaction between different levels of hierarchy in a representation, such as sparse geometry and dense semantic information. </p>
    <p> <b>Persistence</b>: Full joint optimisation is ongoing in the background. Attention can bring into focus area of map. How is this an advantage over LM? </p>
    <p>-> Changing, irregular structure of measurements represented by a factor graph</p> 
    <p>-> Belief propagation: probabilistic message passing for in-place, convergent inference on a factor graph</p> 

    <h3>Gaussian: most efficient way to represent probability distributions
</h3>
    <p>-> Gaussian Belief Propagation: messages take the form of small information vectors and matrices; all the same local operations as in Kalman Filtering or non-linear optimisation.
</p>


    <h2 id="theory">A quick run through of the maths </h2>

    <h3> Factor Graphs </h3>

    <p>Factor graphs are a representation of the factorization of a probability distribution function over a set of variables. A factor graph is a bipartite graph, composed of variable nodes, factor nodes and edges that link variable and factor nodes. In geometric vision, factor graphs are commonly used and each factors represents a probabilistic constraint between a subset of the variables. The topology of the factor graph encodes the factorization of the probability distribution by connecting factor nodes to variabe nodes they depend on. </p>

    <h3> Gaussian Belief Propagation </h3>

    <p>Belief Propagation is a commonly used inference algorithm for estimating the marginal distribution for a set of variables from the joint probability distribution
      <d-footnote>Computing marginal distribution is equivalent to MAP with Gaussians. The MAP of a distribution is the mode, which for a Gaussian is simply the mean. So the MAP is the mean of the marginal distribution. </d-footnote> : </p>

    <d-math block="">
      p(\bold{x}_i) = \int p(\bold{x}) d\bold{x}_1 ... d\bold{x}_{i-1} d\bold{x}_{i+1} ... d\bold{x}_{n}
    </d-math>


    <p>Belief propagation can also be understood as finding from the variational inference perspective as finding a distribution <d-math>q(x)</d-math> which minimises the <d-math>KL(q || p)</d-math>
      <d-footnote>Indeed the algorithm can be derived by minimising the KL subject to the constraints the distribution is normalised and locally consistent. </d-footnote>. </p>

    <p>Intuition of the algorithm. <a
        href="https://github.com/distillpub/template/wiki/Annotated-Formulas">Annotated formula</a> for message passing.</p>

    <p>Factors represent constraints from measurements <d-math>z</d-math> that are modeled by Gaussian measurement models <d-math>z = h(x) + \eta</d-math> where <d-math>\eta \sim N(0, \Sigma_m)</d-math> is zero centered Gaussian noise.</p>

    <p>The belief at a variable node is updated by taking the product of incoming messages from adjacent factor nodes. A message represents... </p>

    <figure class="l-page">
      <d-figure id="gaussprod"></d-figure>
        <figcaption>A landmark is observed by two different cameras, each of which makes an uncertain measurement of the distance to the landmark and the bearing. The location of the cameras are well-known with high confidence. You can change the </figcaption>
      </figure>
    </figure>

    <p>Relinearisation. </p>



    <p> Flexibility in message passing schedule. </p>




    <h2 id="simulations">Simulated geometric estimation problems </h2>

    <p> We demonstrate the positive qualities of GBP through a series of simulated geometric estimation problems. We hope this gives intuition of how inference is performed in GBP. </p>

    <h4 id="1dsurface">1D Surface estimation</h4>

    <p> How to formulate the measurement and smoothness factors. </p>

    <figure class="l-page-outset">
      <d-figure id="gbp1d"></d-figure>
        <figcaption>Surface Fitting simulation.</figcaption>
      </figure>
    </figure>

    <p>Can we relate this to Gaussian processes?</p>


    <h4 id="2drobot">2D Robot Simulation </h4>

    <p> How to formulate 2D measurement factors. </p>

<!--     <p> We can begin with purely linear measurement factors.</p>

    <figure class="l-page-outset" id="robot-container">
      <d-figure id="RobotSim"></d-figure>
        <figcaption>Robot simulation with linear measurement factors.</figcaption>
      </figure>
    </figure>
 -->
    <p> We now introduce non-linear measurement factors.</p>

    <figure class="l-page-outset" id="robot-nonlinear-container">
      <d-figure id="RobotNonlinearSim"></d-figure>
        <figcaption>Robot simulation with non-linear measurement factors.</figcaption>
      </figure>
    </figure>

    <figure class="l-body">
      <d-figure id="Graph"></d-figure>
        <figcaption>d3 graph.</figcaption>
      </figure>
    </figure>


    <p> Lastly we can introduce smoothness factors, for instance enforcing landmarks to be co-linear.</p>

    <figure class="l-page-outset" id="robot-room-container">
      <d-figure id="RobotRoomSim"></d-figure>
        <figcaption>Robot simulation with smoothness constraints between landmarks.</figcaption>
      </figure>
    </figure>

    <h2> Stability </h2>

    <h2 id="discussion">Discussion</h2>
    
    <p> Bundle Adjustment <d-cite key="ortiz2020gbp"></d-cite></p>


  </d-article>


  <d-appendix>
    <h3>Acknowledgments</h3>
    <p>
    </p>

    <h3>Author Contributions</h3>
    <p>
      <b>Research:</b> 
    </p>

    <p>
      <b>Writing & Diagrams:</b> 
    </p>


    <d-footnote-list></d-footnote-list>
    <d-citation-list></d-citation-list>
  </d-appendix>

  <!-- bibliography will be inlined during Distill pipeline's pre-rendering -->
  <d-bibliography src="bibliography.bib"></d-bibliography>

</body>