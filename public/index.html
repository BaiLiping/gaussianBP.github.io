<!doctype html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style id="distill-article-specific-styles">
    .subgrid {
  grid-column: screen; 
  display: grid; 
  grid-template-columns: inherit;
  grid-template-rows: inherit;
  grid-column-gap: inherit;
  grid-row-gap: inherit;
}

d-figure.base-grid {
  grid-column: screen;
  background: hsl(0, 0%, 97%);
  padding: 20px 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

d-figure {
  margin-bottom: 1em;
  position: relative;
}

d-figure > figure {
  margin-top: 0;
  margin-bottom: 0;
}

d-figure.fullscreen{
  grid-column: screen;
}

.shaded-figure {
  background-color: hsl(0, 0%, 97%);
  border-top: 1px solid hsla(0, 0%, 0%, 0.1);
  border-bottom: 1px solid hsla(0, 0%, 0%, 0.1);
  padding: 30px 0;
}

.pointer {
  position: absolute;
  width: 26px;
  height: 26px;
  top: 26px;
  left: -48px;
}


.demo-container {
  display:inline-block;
}

#gbp-container {
  position: relative;
  width: 75%;
  float: left;
  margin-right:5px;
}

#settings-panel {
  position: relative;
  width: 24%;
  float: left;
}

.buttons-panel {
  font-size: 36px; 
}

.center {
  position: absolute;
  left: 0;
  top: 37%;
  width: 100%;
  text-align: center;
  font-size: 18px;
}

.top-left {
  position: absolute;
  left: 0;
  top: 0%;
  width: 100%;
  font-size: 18px;
}

canvas {
  width: 100%;
  height: 100%;
  background-color: #D3D3D3	;
}

#click-canvas {
  cursor: pointer;
}

button {
  width: 100px;
  border: none;
  background-color: white;
  padding: 5px 5px;
  font-size: 36px;
  color: rgb(39, 36, 36);
  font-family: Arial, Arial, Helvetica, sans-serif;
  outline: 0;
  cursor: pointer;
}

input[type=range]::-ms-track {
  width: 100%;
  cursor: pointer;

  /* Hides the slider so custom styles can be added */
  background: transparent;
  border-color: transparent;
  color: transparent;
}

input[type=range] {
  -webkit-appearance: none;
  appearance: none;
  width: 100%;
  height: 5px;
  border-radius: 10%; 
  background: #d3d3d3;
  outline: none; 
  /* opacity: 0.7;  */
  -webkit-transition: .2s; 
  transition: opacity .2s;  
  margin-top: -6px; /* You need to specify a margin in Chrome, but in Firefox and IE it is automatic */
}

input[type=range]::-webkit-slider-thumb {
  -webkit-appearance: none; /* Override default look */
  appearance: none;
  width: 18px; 
  height: 18px; 
  border-radius: 50%;
  background: rgb(209, 117, 12);
  cursor: pointer;
}

/* input[type=range]:hover {
  opacity: 1; 
} */

#alert {
  text-align: center;
  font-size: xx-large;
}

#pointer {
  width: 45px;
}

#wasd {
  width: 45px;
}

#demo-tip{
  float: right;
  display: grid;
  grid-template-columns: 40px auto;
  align-items: center;
  column-gap: 10px;
  margin-bottom: 10px;
}

#left-demo-tip{
  float: left;
  display: grid;
  grid-template-columns: 40px auto;
  align-items: center;
  column-gap: 10px;
  margin-bottom: 10px;
}

#hint {
  position: relative;
  color: rgba(0, 0, 0, 0.6);
  line-height: 1.4em;
  user-select: text;
  font-size: 20px;
}

/* ****************************************
 * On hover tooltip
 ******************************************/
.tooltip {
  position: relative;
  display: inline-block;
  padding: 0px 5px;
  font-size: 36px;
  cursor: pointer;
}

.tooltip .tooltiptext {
  visibility: hidden;
  width: 120px;
  background-color: rgb(39, 36, 36);
  color: #fff;
  text-align: center;
  border-radius: 6px;
  padding: 5px 0;
  
  /* Position the tooltip */
  position: absolute;
  z-index: 1;
  bottom: 100%;
  left: 50%;
  margin-left: -60px;
}

.tooltip:hover .tooltiptext {
  visibility: visible;
  font-size: 40%;
  font-family: Arial, Helvetica, sans-serif;
}


.tooltip-fs {
  position: relative;
  display: inline-block;
  padding: 0px 5px;
  font-size: 100%;
  cursor: pointer;
}

.tooltip-fs .tooltiptext {
  visibility: hidden;
  width: 120px;
  background-color: rgb(39, 36, 36);
  color: #fff;
  text-align: center;
  border-radius: 6px;
  padding: 5px 0;
  
  /* Position the tooltip */
  position: absolute;
  z-index: 1;
  bottom: 100%;
  left: 50%;
  margin-left: -60px;
}

.tooltip-fs:hover .tooltiptext {
  visibility: visible;
  font-size: 40%;
  font-family: Arial, Helvetica, sans-serif;
}



/* ****************************************
 * TOC
 ******************************************/
 @media(max-width: 1199px){
  d-contents {
    display: none;
    justify-self: start;
    align-self: start;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom-width: 1px;
    border-bottom-style: solid;
    border-bottom-color: rgba(0, 0, 0, 0.1);
  }
}
d-contents a:hover {
  border-bottom: none;
}

@media (min-width: 1200px){
  d-contents {
    align-self: start;
    grid-column-start: 1 !important;
    grid-column-end: 4 !important;
    justify-self: end;
    margin-top:  0em;
    padding-right: 3em;
    padding-left: 2em;
    border-right: 1px solid rgba(0, 0, 0, 0.1);
    border-right-width: 1px;
    border-right-style: solid;
    border-right-color: rgba(0, 0, 0, 0.1);
  }
}

d-contents nav h3 {
  margin-top: 0;
  margin-bottom: 1em;
}

d-contents nav div {
  color: rgba(0, 0, 0, 0.8);
  font-weight: bold;
}

d-contents nav a {
  color: rgba(0, 0, 0, 0.8);
  border-bottom: none;
  text-decoration: none;
}

d-contents li {
  list-style-type: none;
}

d-contents ul {
  padding-left: 1em;
}

d-contents nav ul li {
  margin-bottom: .25em;
}

d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6);
}

d-contents nav ul {
  margin-top: 0;
  margin-bottom: 6px;
}


d-contents nav>div {
  display: block;
  outline: none;
  margin-bottom: 0.5em;
}

d-contents nav>div>a {
  font-size: 13px;
  font-weight: 600;
}

d-contents nav>div>a:hover,
d-contents nav>ul>li>a:hover {
    text-decoration: none;
}




  </style>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="https://kit.fontawesome.com/a076d05399.js"></script>
  <script src="https://distill.pub/template.v2.js"></script>
</head>

<body>

  <d-front-matter>
    <script type="text/json">
      {
    "title": "Distill Example",
    "description": "An example project using Webpack, Babel, and Svelte.",
    "password": "gbp",
    "authors": [
        {
            "author": "Joseph Ortiz",
            "authorURL": "http://joeaortiz.github.io",
            "affiliation": "Imperial College London",
            "affiliationURL": "https://wp.doc.ic.ac.uk/robotvision/"
        },
        {
            "author": "Andrew J. Davison",
            "authorURL": "https://www.doc.ic.ac.uk/~ajd/",
            "affiliation": "Imperial College London",
            "affiliationURL": "https://wp.doc.ic.ac.uk/robotvision/"
        }
    ],
    "katex": {
        "delimiters": [
            {
                "left": "$",
                "right": "$",
                "display": false
            },
            {
                "left": "$$",
                "right": "$$",
                "display": true
            }
        ]
    }
}
    </script>
  </d-front-matter>

  <d-title>
    <h1>Gaussian Belief Propagation for Spatial AI</h1>
    <p>A visual introduction to Gaussian Belief Propagation for realtime computer vision. </p>
  </d-title>

  <d-article>
    <d-contents>
      <nav class="l-text toc figcaption">
        <h3>Contents</h3>
        <div><a href="#spatialAI">Spatial AI</a></div>
        <div><a href="#gbp">Gaussian Belief Propagation</a></div>
        <div><a href="#related">Related Work</a></div>
        <div><a href="#theory">A brief Theoretical Background</a></div>
        <div><a href="#simulations">Simulated Geometric Estimation Problems</a></div>
        <ul>
          <li><a href="#1dsurface">1D Surface Fitting</a></li>
          <li><a href="#2drobot">2D Robot Simulation</a></li>
        </ul>
        <div><a href="#discussion">Discussion</a></div>
      </nav>
    </d-contents>

    <h2 id="spatialAI">Spatial AI </h2>
    <p>We want to build intelligent robots that can interact with their environments. An intelligent agent must be capable of spatial reasoning, which requires a component that can build representations of the environment, while also continuosly updating the representation. These representations should capture the geometry, semantic properties, physical properties and other information about the environment.  </p>

    <p>To draw analogy to humans, we have grid cells ect... evidence for map building in human brains. </p>

    <p>We call this general spatial perception capability <i><b>Spatial AI</b></i> <d-cite key="davison2018futuremapping"></d-cite>. We believe that SLAM will evolve into Spatial AI.</p>

    <p>What capabilities do we need: Consistency, long term persistence, abstraction and efficiency</p>
    <p>Why? To enable intelligence! A robot will have a model of the world which is a simulation of reality based on all of its prior knowledge and ongoing experience; and be able to use it to make intelligent e.g. causal inferences about action. I believe in persistent scene representation for spatial reasoning. The foundation for higher level AI?</p>





1. Spatial AI

    

2. Hardware:
we have a strong feeling that algorithms which can operate with purely local computation and in-place data storage on a graph, and communicate via message passing, will fit well with coming computer hardware.



3. Factor graph as master representation:
    - Most accurate, non-linear, general
    - What we need are marginals
    - Enables dynamic computation
    - Batch solution always possible; practical algorithms for real-time either filter or choose
      subset of data.

4. GBP
    
    
    <h3 id="slam">Current Landscape of SLAM Algorithms </h2>

    <p>We begin the discussion of how to build a system capable of Spatial AI by examining existing works in that direction. Note, we have not specified whether the representation should derscribe metric geometry of be abstract. Core capabilities are dense geometry and object class understanding: ElasticFusion, SemanticFusion: how to do it properly?</p>

    <p>What hardware is used in current practical SLAM systems? </p>


    <figure class="l-body">
      <d-figure id=""></d-figure>
        <figcaption>Toy visualisation of data flow and compute on current CPUs / GPUs.</figcaption>
      </figure>
    </figure>



Current prototype Spatial AI systems, attempting to pro- cess this heterogeneous flow of data into complicated per- sistent representations via various estimation techniques, often have severe performance bottlenecks due to limits in the capacities of computation load, data storage or data transfer. 

Two lines of attack: representation and hardware.


SemanticFusion is very complicated and requires heterogeneous computation and a lot of data movement.

Hardware: we need parallelism, but also distributed storage



    Discussion of bits x milimetres metric. 

    What current graph processing hardware is emerging. How would a message passing inference algorithm be well satisfy practical constraints. 

    <figure class="l-body">
      <d-figure id=""></d-figure>
        <figcaption>Toy visualisation of data flow and compute on graph processor.</figcaption>
      </figure>
    </figure>

    <h2 id="gbp">Why Gaussian Belief Propagation? </h2>

    <p>We argue that Gaussian Belief Propagation (GBP) is a strong algorithmic framework for the distributed, generic and incremental probabilistic estimation that we need in Spatial AI. Here we describe how GBP can be the foundation for high performance smart robots and devices which operate within the constraints of real products.</p>

    <h3>Low power requires distributed computation and storage to fit new hardware
    </h3>
    <p> Sending data is costly in power comsumption. </p>
    <p>-> Message passing between processors with local computation and memory, either on a single chip or across multiple simple devices.</p> 

    <h3> Probabilistic fusion of heterogeneous inputs</h3>
    <p> A robot will need to probabilistically fuse different measurements and priors to jointly estimate its current state and optimise its representation of the environment. Bayesian probability theory, from which Gaussian Belief Propagation can be derived, provides a framework to combine constraints and perform probabilistic inference. </p> 

    <h3>We can build persistent and flexible representations from incremental measurements</h3>
    <p> <b>Flexibility</b>: Factor graphs can hold any combination of arbitary entities. This enables a natural interaction between different levels of hierarchy in a representation, such as sparse geometry and dense semantic information. </p>
    <p> <b>Persistence</b>: Full joint optimisation is ongoing in the background. Attention can bring into focus area of map. How is this an advantage over LM? </p>
    <p>-> Changing, irregular structure of measurements represented by a factor graph</p> 
    <p>-> Belief propagation: probabilistic message passing for in-place, convergent inference on a factor graph</p> 

    <h3>Gaussian: most efficient way to represent probability distributions
</h3>
    <p>-> Gaussian Belief Propagation: messages take the form of small information vectors and matrices; all the same local operations as in Kalman Filtering or non-linear optimisation.
</p>


    <h2 id="theory">Factor Graphs and GBP </h2>

    <h3> Factor Graphs and Gaussian Distributions </h3>

    <p>Factor graphs are a representation of the factorization of a probability distribution function over a set of variables. A factor graph is a bipartite graph, composed of variable nodes, factor nodes and edges that link variable and factor nodes. In geometric vision, factor graphs are commonly used and each factors represents a probabilistic constraint between a subset of the variables. The topology of the factor graph encodes the factorization of the probability distribution by connecting factor nodes to variabe nodes they depend on. </p>

    <p>How to relate sparsity in the information form to a graphical model.</p>

    <p>What is inference in a graphical model. Why do we use the information form for GBP.</p>


    <h3> Gaussian Belief Propagation </h3>

    <p>Belief Propagation is a commonly used inference algorithm for estimating the marginal distribution for a set of variables from the joint probability distribution
      <d-footnote>Computing marginal distribution is equivalent to MAP with Gaussians. The MAP of a distribution is the mode, which for a Gaussian is simply the mean. So the MAP is the mean of the marginal distribution. </d-footnote> : </p>

    <d-math block="">
      p(\bold{x}_i) = \int p(\bold{x}) d\bold{x}_1 ... d\bold{x}_{i-1} d\bold{x}_{i+1} ... d\bold{x}_{n}
    </d-math>


    <p>Belief propagation can also be understood as finding from the variational inference perspective as finding a distribution <d-math>q(x)</d-math> which minimises the <d-math>KL(q || p)</d-math> subject to two constraints.
      <d-footnote>The two constraints are that <d-math>q(x)</d-math> is correctly normalised (<d-math>\sum_i q(x_i) = 1</d-math>) and is locally consistent (<d-math>q(x_i) = \sum_{x</d-math>). </d-footnote>. </p>

    <p>Intuition of the algorithm. <a
        href="https://github.com/distillpub/template/wiki/Annotated-Formulas">Annotated formula</a> for message passing.</p>

    <p>Factors represent constraints from measurements <d-math>z</d-math> that are modeled by Gaussian measurement models <d-math>z = h(x) + \eta</d-math> where <d-math>\eta \sim N(0, \Sigma_m)</d-math> is zero centered Gaussian noise.</p>

    <p>The belief at a variable node is updated by taking the product of incoming messages from adjacent factor nodes. A message represents... </p>

    <figure class="l-page">
      <d-figure id="gaussprod"></d-figure>
        <figcaption>A landmark is observed by two different cameras, each of which makes an uncertain measurement of the distance to the landmark and the bearing. The location of the cameras are well-known with high confidence. You can change the </figcaption>
      </figure>
    </figure>

    <p>Relinearisation. Can we visualise the affect that relinearisation has on a message. i.e. it turns a non Gaussian factor distribution into a Gaussian by moment matching. </p>



    <p> Flexibility in message passing schedule. </p>

    <p>Other visualistion ideas: 
        - Factor graph where you message scheduling is determined by the user. i.e. they can move the mouse and messages are sent from variables near the mouse.
        - Spring interpretation of GBP for linear problems.
        - GBP with multiple hierarchies?
      </p>


    <h2 id="simulations">Simulated geometric estimation problems </h2>

    <p> We demonstrate the positive qualities of GBP through a series of simulated geometric estimation problems. We hope this gives intuition of how inference is performed in GBP. </p>

    <h4 id="1dsurface">1D Surface estimation</h4>

    <p> How to formulate the measurement and smoothness factors. </p>

    <figure class="l-page-outset">
      <d-figure id="gbp1d"></d-figure>
        <figcaption>Surface Fitting simulation.</figcaption>
      </figure>
    </figure>

    <p>Can we relate this to Gaussian processes?</p>


    <h4 id="2drobot">2D Robot Simulation </h4>

    <p> How to formulate 2D measurement factors. </p>

<!--     <p> We can begin with purely linear measurement factors.</p>

    <figure class="l-page-outset" id="robot-container">
      <d-figure id="RobotSim"></d-figure>
        <figcaption>Robot simulation with linear measurement factors.</figcaption>
      </figure>
    </figure>
 -->
    <p> We now introduce non-linear measurement factors.</p>

    <figure class="l-page-outset" id="robot-nonlinear-container">
      <d-figure id="RobotNonlinearSim"></d-figure>
        <figcaption>Robot simulation with non-linear measurement factors.</figcaption>
      </figure>
    </figure>

    <figure class="l-body">
      <d-figure id="Graph"></d-figure>
        <figcaption>d3 graph.</figcaption>
      </figure>
    </figure>


    <p> Lastly we can introduce smoothness factors, for instance enforcing landmarks to be co-linear.</p>

    <figure class="l-page-outset" id="robot-room-container">
      <d-figure id="RobotRoomSim"></d-figure>
        <figcaption>Robot simulation with smoothness constraints between landmarks.</figcaption>
      </figure>
    </figure>

    <h2> Stability </h2>

    <h2 id="discussion">Discussion</h2>
    
    <p> Bundle Adjustment <d-cite key="ortiz2020gbp"></d-cite></p>


  </d-article>


  <d-appendix>
    <h3>Acknowledgments</h3>
    <p>
    </p>

    <h3>Author Contributions</h3>
    <p>
      <b>Research:</b> 
    </p>

    <p>
      <b>Writing & Diagrams:</b> 
    </p>


    <d-footnote-list></d-footnote-list>
    <d-citation-list></d-citation-list>
  </d-appendix>

  <!-- bibliography will be inlined during Distill pipeline's pre-rendering -->
  <d-bibliography src="bibliography.bib"></d-bibliography>

<script type="text/javascript" src="index.bundle.js"></script></body>
